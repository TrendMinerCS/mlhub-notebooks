{"metadata":{"kernelspec":{"name":"python_visualization_kubernetes","display_name":"Python With Visualization Libraries on Kubernetes (deprecated)","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"created_by":"eduardo246"},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"fc39c116-9926-4b13-8936-c1b2c3f28334","cell_type":"markdown","source":"\n<img src=\"https://forms.trendminer.com/hs-fs/hubfs/Logo.png?width=1060&name=Logo.png\"  width=\"500\" height=\"500\">","metadata":{},"outputs":[]},{"id":"f547f5ae-ccc5-4102-bd07-a15b512b9cc0","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 1: Import some python packages for data science</span>","metadata":{},"outputs":[]},{"id":"57709bbb-a2d1-476b-b0d7-b7656cd9b357","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:15px;\">TrendMiner Initialization script</span>","metadata":{},"outputs":[]},{"id":"75804beb-89c4-4a1b-969b-49282b67544d","cell_type":"code","source":"# Suggested data science package imports\nimport pandas as pd\nimport numpy as np\n\nfrom datetime import datetime\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n# TrendMiner package import\nimport trendminer\nfrom trendminer.trendminer_client import TrendMinerClient\n\nimport os\n\ntoken = os.environ[\"KERNEL_USER_TOKEN\"]\nserverUrl = os.environ[\"KERNEL_SERVER_URL\"]\n\n# Create TrendMiner API object\nclient = TrendMinerClient(token, serverUrl)","metadata":{"trusted":true},"outputs":[],"execution_count":1},{"id":"8813451b-cdda-4702-a934-5cceea62f1a9","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 2: Import Timeseries Data from TrendHub View</span>","metadata":{},"outputs":[]},{"id":"939e703f-1597-4b2d-8484-3c821ac65fd5","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:15px;\">1 min interpolated data in a dataframe</span>","metadata":{},"outputs":[]},{"id":"190496bd-8506-4a8d-a639-6a362cf97c3f","cell_type":"code","source":"# Loading TrendHub view: R101 View [MLHub]\nfrom trendminer.views.views import Views\n\nviews = Views(client)\ndf = views.load_view('0bc05bde-6237-475a-a560-67836631ecc7')\ndf_train = pd.concat(df)","metadata":{"trusted":true},"outputs":[],"execution_count":2},{"id":"b2e5ef11-c008-4f0a-bdfc-07c16d030f68","cell_type":"code","source":"# Loading TrendHub view: R101 View [MLHub]\nfrom trendminer.views.views import Views\n\nviews = Views(client)\ndf = views.load_view('0bc05bde-6237-475a-a560-67836631ecc7')","metadata":{"trusted":true},"outputs":[],"execution_count":3},{"id":"e1d1e114-4e5f-4e16-9404-d2e8c55ad069","cell_type":"code","source":"df_train","metadata":{"trusted":true},"outputs":[],"execution_count":4},{"id":"db4060cb-42f1-41ee-aa08-cb51d725c597","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 3: Split Data into Training and Testing Dataset</span>","metadata":{},"outputs":[]},{"id":"90cbccbd-732c-4513-bde5-6b1f41e14ea7","cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfeatures = [\"R101_FI1\", \"R101_FI2\"]\nX = df_train[features]\ny = df_train[\"R101_PI\"]\n\n#Splitting the data using the train_test_split function.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True)","metadata":{"trusted":true},"outputs":[],"execution_count":5},{"id":"8b8f640a-8797-493b-9020-27c7e5262873","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 4: Train Model</span>","metadata":{},"outputs":[]},{"id":"b2a6a6bb-db39-4348-97df-0244d8d7e5db","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:15px;\">Using a Gradient Booosting Regressor Model from **ScikitLearn**</span>","metadata":{},"outputs":[]},{"id":"d43cdcda-91f3-4c60-8498-56bfef6dd404","cell_type":"code","source":"# Both Random Forest and Gradient Boosting are ensemble learning methods.\n# Both are based on decision trees.\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n#Create model into as a pipeline\n# This Pipeline function calls for a list of estimators and other operators in the form of tuples...\nestimators = [('model', GradientBoostingRegressor())]\npipeline_obj = Pipeline(estimators)\n\n#Training the model\nmyModel = pipeline_obj.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":6},{"id":"539735c5-5654-4e4e-a949-536f9ee2a24b","cell_type":"code","source":"PredictedY = myModel.predict([20.1, 2.3, 89, 90, 12, 33])","metadata":{"trusted":true},"outputs":[],"execution_count":9},{"id":"a268cb14-830a-4a45-9852-44af5e9ace80","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 5: Evaluate Prediction Effectiveness</span>","metadata":{},"outputs":[]},{"id":"f5b038d6-166c-4f7e-8fec-bd918fbafd81","cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import max_error\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\n\n\ny_pred = myModel.predict(X_test)\n\nprint(\"MSE = \", \"{:.3f}\".format(mean_squared_error(y_test, y_pred)))\nprint(\"Max Error = \", \"{:.3f}\".format(max_error(y_test, y_pred)))\nprint(\"Mean Abs Error = \", \"{:.3f}\".format(mean_absolute_error(y_test, y_pred)))\n\n\nprint(\"\\nCoefficient of Determination\")\nprint(\"R2 =\", \"{:.3f}\".format(r2_score(y_test, y_pred)))\n","metadata":{"trusted":true},"outputs":[],"execution_count":7},{"id":"59f311bc-52fa-4077-b189-8f9b850f6e13","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 6: Convert ScikitLearn Model Pipeline to PMML</span>","metadata":{},"outputs":[]},{"id":"134d1cf1-0e3d-48da-905e-63111d994b2e","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:15px;\">**PMML** format accepted by TrendMiner</span>","metadata":{},"outputs":[]},{"id":"0f880288-d201-40d6-878a-6d36a1dfeaea","cell_type":"code","source":"# PMML\n\nfrom nyoka import skl_to_pmml\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#Converting model to pmml\nmodel_name = \"R101_PI_GradiantBoosting\"\n\nskl_to_pmml(pipeline=myModel,\n            col_names=features,\n            target_name=\"PredictedPressure\",\n            pmml_f_name=\"hello.pmml\",\n            model_name=model_name,\n            description=\"test_description\")","metadata":{"trusted":true},"outputs":[],"execution_count":8},{"id":"3313e6bb-1b0e-4c6a-9ac7-48b1088784c0","cell_type":"markdown","source":"<span style=\"font-family:Times New Roman; font-size:30px;\">Step 7: Model Deployment</span>","metadata":{},"outputs":[]},{"id":"4d52159e-ff27-46f0-b876-30cf70d8a832","cell_type":"code","source":"from trendminer.ml.models import ZementisModels\n\n#Deploying model with Zementis\nwith open(\"hello.pmml\",\"r\") as f:\n    string = f.read()\n\n# But first, lets delete the model from pervious demo\nzementis = ZementisModels(client)\ntry:\n    zementis.delete_model(model_name)\nexcept trendminer.ml.models.exceptions.MLModelNotFoundException:\n    pass\n\n# Now we can deploy the model and voila!\nmodels = ZementisModels(client)\nmodel_id = models.deploy_model(string)\nmodel_details = models.model_details(model_id)","metadata":{"trusted":true},"outputs":[],"execution_count":9}]}