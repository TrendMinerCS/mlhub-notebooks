{
 "metadata": {
  "kernelspec": {
   "name": "python_311",
   "display_name": "Python 3.11 on Kubernetes",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "created_by": "wdaniels"
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "7a544ed7-030c-446d-b9cf-6e680e1fec3b",
   "cell_type": "markdown",
   "source": "# Get interpolated data\n\nRather than getting time series data from a view, it is possible to retrieve time series data directly using requests. Below is a general function that will return a pandas DataFrame of regularly interpolated time series data for given input tags. You can paste this function definition in your MLHub scripts to have an easier and more flexible way to retrieve time series data.",
   "metadata": {}
  },
  {
   "id": "f1390d0c-c44a-4454-ae8d-e25752f8caa3",
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib3\n",
    "\n",
    "\n",
    "def get_data(\n",
    "    tagnames: List[str],\n",
    "    start: pd.Timestamp,\n",
    "    end: pd.Timestamp,\n",
    "    freq: pd.Timedelta,\n",
    "    tz: Union[str, None] = \"UTC\",\n",
    "    verify: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve interpolated time series data from selected tags, paging transparently\n",
    "    for long time ranges by following the API's `nextStartDate`.\n",
    "    \"\"\"\n",
    "    # 1) Localize / round inputs\n",
    "    if tz:\n",
    "        if start.tzinfo is None:\n",
    "            start = start.tz_localize(tz)\n",
    "        if end.tzinfo is None:\n",
    "            end = end.tz_localize(tz)\n",
    "    start = start.round(freq)\n",
    "    end   = end.round(freq)\n",
    "\n",
    "    # 2) Auth + optional SSL‐skip\n",
    "    headers = {\"Authorization\": f\"Bearer {os.environ['KERNEL_USER_TOKEN']}\"}\n",
    "    if not verify:\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    series_list = []\n",
    "    for tagname in tagnames:\n",
    "        # fetch tag metadata\n",
    "        details = requests.get(\n",
    "            f\"{os.environ['KERNEL_SERVER_URL']}/hps/api/tags/details\",\n",
    "            headers=headers,\n",
    "            params={\"tagName\": tagname},\n",
    "            verify=verify,\n",
    "        ).json()\n",
    "\n",
    "        chunks = []\n",
    "        next_start = start\n",
    "\n",
    "        while True:\n",
    "            payload = {\n",
    "                \"tag\": {\n",
    "                    \"id\": details[\"id\"],\n",
    "                    \"shift\": 0,\n",
    "                    \"interpolationType\": details[\"interpolationType\"],\n",
    "                },\n",
    "                \"timePeriod\": {\n",
    "                    \"startDate\": next_start.isoformat(timespec=\"milliseconds\"),\n",
    "                    \"endDate\":   end.isoformat(timespec=\"milliseconds\"),\n",
    "                },\n",
    "                \"step\": int(freq.total_seconds()),\n",
    "            }\n",
    "            data = requests.post(\n",
    "                f\"{os.environ['KERNEL_SERVER_URL']}/compute/interpolatedData/paged\",\n",
    "                headers=headers,\n",
    "                json=payload,\n",
    "                verify=verify,\n",
    "            ).json()\n",
    "\n",
    "            # **NEW**: only build a chunk when there *are* values\n",
    "            vals = data.get(\"values\", [])\n",
    "            if vals:\n",
    "                chunk = (\n",
    "                    pd.DataFrame(vals)\n",
    "                      .assign(ts=lambda df: pd.to_datetime(df[\"ts\"]))\n",
    "                      .set_index(\"ts\")[\"value\"]\n",
    "                )\n",
    "                chunks.append(chunk)\n",
    "\n",
    "            # advance to next page (or break if none)\n",
    "            next_sd = data.get(\"nextStartDate\")\n",
    "            if not next_sd:\n",
    "                break\n",
    "\n",
    "            next_start = pd.to_datetime(next_sd)\n",
    "            if next_start >= end:\n",
    "                break\n",
    "\n",
    "            time.sleep(0.1)\n",
    "\n",
    "        # if we never got *any* data, make an empty Series\n",
    "        if chunks:\n",
    "            tag_series = pd.concat(chunks)\n",
    "        else:\n",
    "            tag_series = pd.Series(dtype=float, name=tagname)\n",
    "\n",
    "        tag_series.name = tagname\n",
    "\n",
    "        # map codes → names for STRING/DIGITAL tags\n",
    "        if details.get(\"type\") in (\"DIGITAL\", \"STRING\"):\n",
    "            states = {s[\"Code\"]: s[\"Name\"] for s in details.get(\"States\", [])}\n",
    "            tag_series = tag_series.map(states)\n",
    "\n",
    "        series_list.append(tag_series)\n",
    "\n",
    "    # combine into one DataFrame, convert tz\n",
    "    df = pd.concat(series_list, axis=1)\n",
    "    if tz:\n",
    "        df.index = df.index.tz_convert(tz)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "id": "bc225f83-1946-4dd5-971d-cac8d248d8e2",
   "cell_type": "markdown",
   "source": "Below is a example call to our `get_data` function. We retrieve the time series data for 3 tags for January 2023, at a 5 minute resolution, in our local timezone.",
   "metadata": {}
  },
  {
   "id": "509f3eba-8450-4796-823a-d0fce59bf691",
   "cell_type": "code",
   "source": "df = get_data(\n    tagnames=[\"TM4-BP2-PRODUCT.1\", \"TM4-BP2-LEVEL.1\", \"TM4-BP2-CONC.1\"],\n    start=pd.Timestamp(\"2023-01-01\"),\n    end=pd.Timestamp(\"2023-02-01\"),\n    freq=pd.Timedelta(minutes=5),\n    tz=\"Europe/Brussels\",\n)\n\ndf.head()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": 17
  }
 ]
}
