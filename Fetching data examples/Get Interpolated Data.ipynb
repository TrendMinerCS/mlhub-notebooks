{
 "metadata": {
  "kernelspec": {
   "name": "python_311",
   "display_name": "Python 3.11 on Kubernetes",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "created_by": "wdaniels"
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "7a544ed7-030c-446d-b9cf-6e680e1fec3b",
   "cell_type": "markdown",
   "source": "# Get interpolated data\n\nRather than getting time series data from a view, it is possible to retrieve time series data directly using requests. Below is a general function that will return a pandas DataFrame of regularly interpolated time series data for given input tags. You can paste this function definition in your MLHub scripts to have an easier and more flexible way to retrieve time series data.",
   "metadata": {}
  },
  {
   "id": "f1390d0c-c44a-4454-ae8d-e25752f8caa3",
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import urllib3\n",
    "\n",
    "\n",
    "def get_data(tagnames: list, start: pd.Timestamp, end: pd.Timestamp, freq: pd.Timedelta, tz: \"UTC\", verify=True) -> pd.DataFrame:\n",
    "    \"\"\"Retrieve interpolated time series data from selected tags\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tagnames : list of str\n",
    "        Tags for which to retrieve the data\n",
    "    start : pandas.Timestamp\n",
    "        Start of the interval for which to retrieve the data. Localized to `tz` if not timezone-aware.\n",
    "    end : pandas.Timestamp\n",
    "        End of the interval for which to retrieve the data. Localized to `tz` if not timezone-aware.\n",
    "    freq : pd.Timdelta\n",
    "        Frequency of the interpolated data. Interpolated data is exclusively generated from the indexed data in TrendMiner. \n",
    "        Setting a low value does not result raw time series data.\n",
    "    tz : str, default 'UTC'\n",
    "        Timezone for the timestamps in the returned DataFrame\n",
    "    verify : bool, default True\n",
    "        Whether requests should perform SSL certificate validation. Can be turned off in case you are getting errors about certificate issues.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with a DatetimeIndex in the selected timezone, with a data column (float or str) for each tag name\n",
    "    \"\"\"\n",
    "    # Add timestamp timezones if not provided\n",
    "    if not start.tz:\n",
    "        start = start.tz_localize(tz)\n",
    "    if not end.tz:\n",
    "        end = end.tz_localize(tz)\n",
    "\n",
    "    # Rounding to get regular timestamps\n",
    "    start = start.round(freq)\n",
    "    end = end.round(freq)\n",
    "\n",
    "    # This authentication header we need to add to every request\n",
    "    headers = {'Authorization': f'Bearer {os.environ[\"KERNEL_USER_TOKEN\"]}'}\n",
    "\n",
    "    # Turn off for verification being turned off\n",
    "    if verify is False:\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "    tag_series_list = []\n",
    "    for tagname in tagnames:\n",
    "        # Get tag details required to retrieve tag data\n",
    "        tag_details_response = requests.get(\n",
    "            url=f'{os.environ[\"KERNEL_SERVER_URL\"]}/hps/api/tags/details',\n",
    "            headers=headers,\n",
    "            params={'tagName': tagname},\n",
    "            verify=verify,\n",
    "        )\n",
    "        tag_details = tag_details_response.json()\n",
    "\n",
    "        # Retrieve tag data; data is split in pages if the request is too large\n",
    "        tag_series_chunks = []\n",
    "        current_start = start\n",
    "        while True:\n",
    "            tag_data_response = requests.post(\n",
    "                url=f'{os.environ[\"KERNEL_SERVER_URL\"]}/compute/interpolatedData/paged',\n",
    "                headers=headers,\n",
    "                json={\n",
    "                    \"tag\": {\n",
    "                        \"id\": tag_details[\"id\"],\n",
    "                        \"shift\": 0,  # tag timeshift in seconds; typically 0\n",
    "                        \"interpolationType\": tag_details[\"interpolationType\"],\n",
    "                    },\n",
    "                    \"timePeriod\": {\n",
    "                        \"startDate\": current_start.isoformat(timespec=\"milliseconds\"),\n",
    "                        \"endDate\": end.isoformat(timespec=\"milliseconds\")\n",
    "                    },\n",
    "                    \"step\": freq.total_seconds(),  # Data frequency in seconds\n",
    "                },\n",
    "                verify=verify,\n",
    "            )\n",
    "            tag_data = tag_data_response.json()\n",
    "\n",
    "            # Convert response to Series\n",
    "            tag_series_chunk = (\n",
    "                pd.DataFrame(tag_data[\"values\"])  # dict to DataFrame\n",
    "                .assign(ts=lambda df: pd.to_datetime(df[\"ts\"]))  # conver str to timestamps\n",
    "                .set_index(\"ts\")  # set timestamp as index\n",
    "                [\"value\"] # DataFrame -> Series\n",
    "            )\n",
    "            tag_series_chunks.append(tag_series_chunk)\n",
    "\n",
    "            # Check if there is an additional page; if not, stop the loop\n",
    "            try:\n",
    "                current_start = pd.Timestamp(tag_data[\"nextStartDate\"])\n",
    "            except KeyError:\n",
    "                break\n",
    "\n",
    "        # Concat the different chunks of a single tag\n",
    "        tag_series = pd.concat(tag_series_chunks)\n",
    "        tag_series.name = tagname    \n",
    "\n",
    "        # Retrieve the correct string for text tags\n",
    "        if tag_details[\"type\"] in [\"DIGITAL\", \"STRING\"]:\n",
    "            states = {state[\"Code\"]: state[\"Name\"] for state in tag_details[\"States\"]}\n",
    "            tag_series = tag_series.map(states)\n",
    "\n",
    "        # Store data\n",
    "        tag_series_list.append(tag_series)\n",
    "            \n",
    "    # Concat the different tags into a single DataFrame\n",
    "    df = pd.concat(tag_series_list, axis=1)\n",
    "\n",
    "    # Set timezone\n",
    "    df.index = df.index.tz_convert(tz)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "id": "bc225f83-1946-4dd5-971d-cac8d248d8e2",
   "cell_type": "markdown",
   "source": "Below is a example call to our `get_data` function. We retrieve the time series data for 3 tags for January 2023, at a 5 minute resolution, in our local timezone.",
   "metadata": {}
  },
  {
   "id": "509f3eba-8450-4796-823a-d0fce59bf691",
   "cell_type": "code",
   "source": "df = get_data(\n    tagnames=[\"TM4-BP2-PRODUCT.1\", \"TM4-BP2-LEVEL.1\", \"TM4-BP2-CONC.1\"],\n    start=pd.Timestamp(\"2023-01-01\"),\n    end=pd.Timestamp(\"2023-02-01\"),\n    freq=pd.Timedelta(minutes=5),\n    tz=\"Europe/Brussels\",\n)\n\ndf.head()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": 17
  }
 ]
}
