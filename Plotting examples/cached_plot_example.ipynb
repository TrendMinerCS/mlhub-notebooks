{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Caching plots with context item attachments\n",
    "This notebook demonstrates how to wrap any Plotly chart-building routine in a single cache-and-retrieve utility with TrendMiner context items. After you define your own make_fig() function (which loads data and returns a Plotly Figure), you call cache_context_plot(...) once—behind the scenes it will:\n",
    "\t1.\tCheck whether a previous JSON attachment exists and how old it is.\n",
    "\t2.\tRegenerate and upload a fresh figure only if the cache is missing or stale.\n",
    "\t3.\tDownload and display the cached figure instantly when it’s up to date.\n",
    "\n",
    "With this pattern, you get the speed of cached charts and the flexibility to redraw whenever your data changes—all in one clean, reusable function."
   ],
   "id": "678c67d1f1076708"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T15:37:18.903467Z",
     "start_time": "2025-05-19T15:37:18.877183Z"
    }
   },
   "source": [
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "import pytz\n",
    "import requests\n",
    "import plotly.io as pio\n",
    "\n",
    "def cache_context_plot(\n",
    "    make_fig, \n",
    "    context_item_id, \n",
    "    server_url=None, \n",
    "    token=None, \n",
    "    filename=\"cached_plotly_output\", \n",
    "    extension=\"json\", \n",
    "    refresh_delta=timedelta(hours=1)\n",
    "):\n",
    "    \"\"\"\n",
    "    Cache a Plotly figure as a TrendMiner context‐item attachment,\n",
    "    regenerating only if older than refresh_delta.\n",
    "    \"\"\"\n",
    "    server = server_url or os.environ[\"KERNEL_SERVER_URL\"]\n",
    "    tok    = token     or os.environ[\"KERNEL_USER_TOKEN\"]\n",
    "    hdrs   = {\"Authorization\": f\"Bearer {tok}\"}\n",
    "\n",
    "    # 1) list existing attachments\n",
    "    resp = requests.get(\n",
    "        f\"{server}/context/data/{context_item_id}/attachments\",\n",
    "        headers=hdrs,\n",
    "        params={\"size\": 1000}\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    att_id, mtime = None, None\n",
    "    for itm in resp.json()[\"content\"]:\n",
    "        if itm[\"name\"] == filename and itm[\"extension\"] == extension:\n",
    "            att_id = itm[\"identifier\"]\n",
    "            mtime  = parser.isoparse(itm[\"lastModifiedDate\"])\n",
    "            break\n",
    "\n",
    "    # 2) decide whether to refresh\n",
    "    now = pytz.utc.localize(datetime.utcnow())\n",
    "    needs_refresh = (mtime is None) or ((mtime + refresh_delta) < now)\n",
    "\n",
    "    if needs_refresh:\n",
    "        logging.info(\"Regenerating and uploading fresh plot…\")\n",
    "        fig_json = pio.to_json(make_fig())\n",
    "\n",
    "        # delete old if present\n",
    "        if att_id:\n",
    "            requests.delete(\n",
    "                f\"{server}/context/data/{context_item_id}/attachments/{att_id}\",\n",
    "                headers=hdrs\n",
    "            ).raise_for_status()\n",
    "            logging.info(f\"Deleted old attachment {att_id}\")\n",
    "\n",
    "        # upload new\n",
    "        upload_resp = requests.post(\n",
    "            f\"{server}/context/data/{context_item_id}/attachments\",\n",
    "            headers={**hdrs, \"content-type\": \"application/octet-stream\"},\n",
    "            files={\"file\": (f\"{filename}.{extension}\", fig_json)},\n",
    "            params={\"name\": filename, \"extension\": extension}\n",
    "        )\n",
    "        upload_resp.raise_for_status()\n",
    "        logging.info(\"Uploaded new cache\")\n",
    "        return pio.from_json(fig_json)\n",
    "\n",
    "    else:\n",
    "        logging.info(\"Loading figure from cache…\")\n",
    "        dl_resp = requests.get(\n",
    "            f\"{server}/context/data/{context_item_id}/attachments/{att_id}/download\",\n",
    "            headers=hdrs\n",
    "        )\n",
    "        dl_resp.raise_for_status()\n",
    "        raw = dl_resp.content.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "        # robustly extract JSON between first { and last }\n",
    "        start = raw.find(\"{\")\n",
    "        end   = raw.rfind(\"}\") + 1\n",
    "        json_str = raw[start:end]\n",
    "\n",
    "        return pio.from_json(json_str)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytz'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdatetime\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdateutil\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m parser\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpytz\u001B[39;00m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mrequests\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplotly\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mio\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpio\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'pytz'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from trendminer.views.views import Views\n",
    "import plotly.express as px\n",
    "\n",
    "def make_fig():\n",
    "    # load your data however you like…\n",
    "    views = Views(TrendMinerClient(os.environ[\"KERNEL_USER_TOKEN\"], os.environ[\"KERNEL_SERVER_URL\"]))\n",
    "    df = views.load_view(\"4b950668-3885-44e6-bf5d-598756836741\")[0]\n",
    "    df_long = (\n",
    "        df.reset_index()\n",
    "          .melt(id_vars=\"index\",\n",
    "                value_vars=[\"[CS]BA:CONC.1\",\"[CS]BA:LEVEL.1\",\"[CS]BA:TEMP.1\"],\n",
    "                var_name=\"Parameter\", value_name=\"Value\")\n",
    "    )\n",
    "    fig = px.line(df_long, x=\"index\", y=\"Value\", color=\"Parameter\",\n",
    "                  title=\"Concentration, Level & Temperature over Time\")\n",
    "    fig.update_layout(xaxis=dict(rangeslider=dict(visible=True)))\n",
    "    return fig\n",
    "\n",
    "fig = cache_context_plot(\n",
    "    make_fig,\n",
    "    context_item_id=\"f078aa08-65c5-4247-96f9-ddef972cb73c\",\n",
    "    refresh_delta=timedelta(minutes=1)\n",
    ")\n",
    "fig.show()"
   ],
   "id": "6cc44921b189e490"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
